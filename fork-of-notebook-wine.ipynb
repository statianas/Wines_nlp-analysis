{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gensim==3.8.3\nimport gensim\ngensim.__version__","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:41.871286Z","iopub.execute_input":"2022-12-20T23:43:41.872666Z","iopub.status.idle":"2022-12-20T23:43:52.459446Z","shell.execute_reply.started":"2022-12-20T23:43:41.872617Z","shell.execute_reply":"2022-12-20T23:43:52.458457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip ","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:52.461712Z","iopub.execute_input":"2022-12-20T23:43:52.462108Z","iopub.status.idle":"2022-12-20T23:43:55.241691Z","shell.execute_reply.started":"2022-12-20T23:43:52.462067Z","shell.execute_reply":"2022-12-20T23:43:55.240166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! unzip /kaggle/working/mallet-2.0.8.zip ","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:55.243753Z","iopub.execute_input":"2022-12-20T23:43:55.244902Z","iopub.status.idle":"2022-12-20T23:43:57.904882Z","shell.execute_reply.started":"2022-12-20T23:43:55.244849Z","shell.execute_reply":"2022-12-20T23:43:57.903474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!ls /kaggle/working/mallet-2.0.8","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:57.908313Z","iopub.execute_input":"2022-12-20T23:43:57.908741Z","iopub.status.idle":"2022-12-20T23:43:57.913497Z","shell.execute_reply.started":"2022-12-20T23:43:57.908684Z","shell.execute_reply":"2022-12-20T23:43:57.912695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!conda update --force -y conda","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:57.914957Z","iopub.execute_input":"2022-12-20T23:43:57.915524Z","iopub.status.idle":"2022-12-20T23:43:57.926255Z","shell.execute_reply.started":"2022-12-20T23:43:57.915492Z","shell.execute_reply":"2022-12-20T23:43:57.925348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!wget https://anaconda.org/conda-forge/gensim/3.8.3/download/win-64/gensim-3.8.3-py37h1834ac0_0.tar.bz2","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:57.927708Z","iopub.execute_input":"2022-12-20T23:43:57.928079Z","iopub.status.idle":"2022-12-20T23:43:57.940515Z","shell.execute_reply.started":"2022-12-20T23:43:57.928046Z","shell.execute_reply":"2022-12-20T23:43:57.939545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!conda install /kaggle/working/gensim-3.8.3-py37h1834ac0_0.tar.bz2","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:57.942308Z","iopub.execute_input":"2022-12-20T23:43:57.942703Z","iopub.status.idle":"2022-12-20T23:43:57.955959Z","shell.execute_reply.started":"2022-12-20T23:43:57.942668Z","shell.execute_reply":"2022-12-20T23:43:57.954751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\nfrom nltk.corpus import stopwords\nfrom pprint import pprint\nimport spacy\nimport re\nimport sys","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:57.957738Z","iopub.execute_input":"2022-12-20T23:43:57.958425Z","iopub.status.idle":"2022-12-20T23:43:57.968294Z","shell.execute_reply.started":"2022-12-20T23:43:57.958364Z","shell.execute_reply":"2022-12-20T23:43:57.967389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk; nltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:57.969912Z","iopub.execute_input":"2022-12-20T23:43:57.970269Z","iopub.status.idle":"2022-12-20T23:43:57.986553Z","shell.execute_reply.started":"2022-12-20T23:43:57.970237Z","shell.execute_reply":"2022-12-20T23:43:57.985745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:57.990596Z","iopub.execute_input":"2022-12-20T23:43:57.991063Z","iopub.status.idle":"2022-12-20T23:43:57.996275Z","shell.execute_reply.started":"2022-12-20T23:43:57.991018Z","shell.execute_reply":"2022-12-20T23:43:57.995295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import logging\n\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:57.997619Z","iopub.execute_input":"2022-12-20T23:43:57.998578Z","iopub.status.idle":"2022-12-20T23:43:58.007775Z","shell.execute_reply.started":"2022-12-20T23:43:57.998543Z","shell.execute_reply":"2022-12-20T23:43:58.006902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sent_to_words(sentences):\n    for sentence in sentences:\n        yield (gensim.utils.simple_preprocess(str(sentence), deacc=True))\n\n\ndef remove_stopwords(texts):\n    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n\n\ndef make_bigrams(texts):\n    return [bigram_mod[doc] for doc in texts]\n\n\ndef make_trigrams(texts):\n    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n\n\ndef lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n    \"\"\"https://spacy.io/api/annotation\"\"\"\n    texts_out = []\n    for sent in texts:\n        doc = nlp(\" \".join(sent))\n        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n    return texts_out","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.009454Z","iopub.execute_input":"2022-12-20T23:43:58.010290Z","iopub.status.idle":"2022-12-20T23:43:58.024786Z","shell.execute_reply.started":"2022-12-20T23:43:58.010256Z","shell.execute_reply":"2022-12-20T23:43:58.024044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# orig_stdout = sys.stdout\n# f = open('help.txt', 'w', encoding=\"utf-8\")\n# sys.stdout = f\n# language = \"en\"\n# stop_words = stopwords.words('english')\n# data = pd.read_csv('/kaggle/input/datas/wine_part_new_1.csv', delimiter=\";\", low_memory=False)  # '/home/lily/Downloads/wines.csv'\n# wine = data.iloc[1][1]","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.026462Z","iopub.execute_input":"2022-12-20T23:43:58.027097Z","iopub.status.idle":"2022-12-20T23:43:58.037359Z","shell.execute_reply.started":"2022-12-20T23:43:58.027051Z","shell.execute_reply":"2022-12-20T23:43:58.036494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!sudo pip install git+https://github.com/statianas/pyLDAvis@master\n#!sudo pip install pyLDAvis\n#print(gensim.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.038946Z","iopub.execute_input":"2022-12-20T23:43:58.039630Z","iopub.status.idle":"2022-12-20T23:43:58.052165Z","shell.execute_reply.started":"2022-12-20T23:43:58.039594Z","shell.execute_reply":"2022-12-20T23:43:58.051187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pyLDAvis\nimport pyLDAvis.gensim\nimport os\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.053701Z","iopub.execute_input":"2022-12-20T23:43:58.054087Z","iopub.status.idle":"2022-12-20T23:43:58.065678Z","shell.execute_reply.started":"2022-12-20T23:43:58.054053Z","shell.execute_reply":"2022-12-20T23:43:58.064502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ.update({'MALLET_HOME':r'/kaggle/working/mallet-2.0.8/'})\n#mallet_path = '\\kaggle\\input\\mallet\\mallet-2.0.8\\bin\\mallet' # update this path\nmallet_path = '/kaggle/working/mallet-2.0.8/bin/mallet' # update this path\nprint(gensim.__version__)\n#ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.067444Z","iopub.execute_input":"2022-12-20T23:43:58.068095Z","iopub.status.idle":"2022-12-20T23:43:58.077806Z","shell.execute_reply.started":"2022-12-20T23:43:58.068051Z","shell.execute_reply":"2022-12-20T23:43:58.077109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mallet_model(mallet_path, corpus, num_topics, id2word):\n#     print(\"hello!\")\n    model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n    return model\n#     print(\"hello!!\")\n#     with open('data.pickle', 'wb') as f_1:\n#         pickle.dump(data, f_1)\n#     print(\"hello!!!\")\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.079335Z","iopub.execute_input":"2022-12-20T23:43:58.079898Z","iopub.status.idle":"2022-12-20T23:43:58.091808Z","shell.execute_reply.started":"2022-12-20T23:43:58.079864Z","shell.execute_reply":"2022-12-20T23:43:58.091056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import multiprocessing\nimport time\nimport threading","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.093337Z","iopub.execute_input":"2022-12-20T23:43:58.093993Z","iopub.status.idle":"2022-12-20T23:43:58.109587Z","shell.execute_reply.started":"2022-12-20T23:43:58.093957Z","shell.execute_reply":"2022-12-20T23:43:58.108697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n    \"\"\"\n    Compute c_v coherence for various number of topics\n\n    Parameters:\n    ----------\n    dictionary : Gensim dictionary\n    corpus : Gensim corpus\n    texts : List of input texts\n    limit : Max num of topics\n\n    Returns:\n    -------\n    model_list : List of LDA topic models\n    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n    \"\"\"\n    coherence_values = []\n    model_list = []\n    for num_topics in range(start, limit, step):\n#         model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n#                                                         id2word=id2word,\n#                                                         num_topics=num_topics,\n#                                                             workers = 2,\n#                                                         random_state=100,\n#                                                         chunksize=100,\n#                                                         passes=10,\n#                                                         alpha='symmetric',\n#                                                         per_word_topics=True)\n        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                                        id2word=id2word,\n                                                        num_topics=num_topics,\n                                                        random_state=100,\n                                                        chunksize=100,\n                                                        passes=10,\n                                                        alpha='auto',\n                                                        iterations = 1500,\n                                                        per_word_topics=True)\n        #model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n        model_list.append(model)\n        #coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n        coherence_values.append(coherencemodel.get_coherence())\n\n    return model_list, coherence_values","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.111163Z","iopub.execute_input":"2022-12-20T23:43:58.111730Z","iopub.status.idle":"2022-12-20T23:43:58.124403Z","shell.execute_reply.started":"2022-12-20T23:43:58.111695Z","shell.execute_reply":"2022-12-20T23:43:58.123403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_topics_sentences(ldamodel, corpus, texts):\n    # Init output\n    sent_topics_df = pd.DataFrame()\n\n    # Get main topic in each document\n    for i, row in enumerate(ldamodel[corpus]):\n        #print(\"old\", row)\n        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n        #print(\"new\", row)\n        # Get the Dominant topic, Perc Contribution and Keywords for each document\n        for j, (topic_num, prop_topic) in enumerate(row):\n            if j == 0:  # => dominant topic\n                wp = ldamodel.show_topic(topic_num)\n                topic_keywords = \", \".join([word for word, prop in wp])\n                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n            else:\n                break\n    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n    # Add original text to the end of the output\n    contents = pd.Series(texts)\n    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n    return(sent_topics_df)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.126565Z","iopub.execute_input":"2022-12-20T23:43:58.127323Z","iopub.status.idle":"2022-12-20T23:43:58.143594Z","shell.execute_reply.started":"2022-12-20T23:43:58.127288Z","shell.execute_reply":"2022-12-20T23:43:58.142316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**","metadata":{}},{"cell_type":"code","source":"#!pip install dataframe_image","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.147013Z","iopub.execute_input":"2022-12-20T23:43:58.147629Z","iopub.status.idle":"2022-12-20T23:43:58.158580Z","shell.execute_reply.started":"2022-12-20T23:43:58.147594Z","shell.execute_reply":"2022-12-20T23:43:58.157714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import threading\nimport pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nfrom multiprocessing import Process, Queue\nmax_i = 0\nQ = Queue()","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.160071Z","iopub.execute_input":"2022-12-20T23:43:58.160862Z","iopub.status.idle":"2022-12-20T23:43:58.171669Z","shell.execute_reply.started":"2022-12-20T23:43:58.160793Z","shell.execute_reply":"2022-12-20T23:43:58.170889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def give_optimal_model(model_list, coherence_values):\n    max = -1\n    global max_i\n    optimal_model = model_list[0]\n    for i in range(0, len(model_list)):\n        if coherence_values[i] > max + 0.0001:\n            max = coherence_values[i]\n            optimal_model = model_list[i]\n            max_i = i\n            #print(coherence_values[i])\n    #print(max)\n    return optimal_model","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.173338Z","iopub.execute_input":"2022-12-20T23:43:58.173800Z","iopub.status.idle":"2022-12-20T23:43:58.186387Z","shell.execute_reply.started":"2022-12-20T23:43:58.173754Z","shell.execute_reply":"2022-12-20T23:43:58.185142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import plotly.figure_factory as ff","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.188203Z","iopub.execute_input":"2022-12-20T23:43:58.189223Z","iopub.status.idle":"2022-12-20T23:43:58.203283Z","shell.execute_reply.started":"2022-12-20T23:43:58.189175Z","shell.execute_reply":"2022-12-20T23:43:58.202331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install -U kaleido","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.205102Z","iopub.execute_input":"2022-12-20T23:43:58.205829Z","iopub.status.idle":"2022-12-20T23:43:58.215798Z","shell.execute_reply.started":"2022-12-20T23:43:58.205781Z","shell.execute_reply":"2022-12-20T23:43:58.215023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir html","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:58.217668Z","iopub.execute_input":"2022-12-20T23:43:58.218802Z","iopub.status.idle":"2022-12-20T23:43:59.339200Z","shell.execute_reply.started":"2022-12-20T23:43:58.218764Z","shell.execute_reply":"2022-12-20T23:43:59.337603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir png","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:43:59.341191Z","iopub.execute_input":"2022-12-20T23:43:59.341617Z","iopub.status.idle":"2022-12-20T23:44:00.466684Z","shell.execute_reply.started":"2022-12-20T23:43:59.341575Z","shell.execute_reply":"2022-12-20T23:44:00.465325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir csv","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:44:00.474102Z","iopub.execute_input":"2022-12-20T23:44:00.474533Z","iopub.status.idle":"2022-12-20T23:44:01.611598Z","shell.execute_reply.started":"2022-12-20T23:44:00.474489Z","shell.execute_reply":"2022-12-20T23:44:01.610072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import signal\n\nclass TimeoutException(Exception):\n    pass\n\ndef timeout_handler(signum, frame):\n    raise TimeoutException\n\nsignal.signal(signal.SIGALRM, timeout_handler)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:44:01.614102Z","iopub.execute_input":"2022-12-20T23:44:01.614697Z","iopub.status.idle":"2022-12-20T23:44:01.626896Z","shell.execute_reply.started":"2022-12-20T23:44:01.614637Z","shell.execute_reply":"2022-12-20T23:44:01.626123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for num_f in range(3,4):\n    orig_stdout = sys.stdout\n    str1 = str(\"part_new_\") + str(num_f) + str(\".txt\")\n    f = open(str1, 'w', encoding=\"utf-8\")\n    sys.stdout = f\n    language = \"en\"\n    stop_words = stopwords.words('english')\n    data = pd.read_csv(\"/kaggle/input/datas/wine_part_new_\"+ str(num_f) + \".csv\", delimiter=\";\", low_memory=False)  # '/home/lily/Downloads/wines.csv'\n    data1 = data.values.tolist()\n    wine = data.iloc[1][1]\n    mas_notes = []\n    flag = 0\n    #print(type(wine))\n    #print(wine, sep=\"\\n\")\n    for row in data.itertuples():\n        if (flag == 0) and (str(row[2]) != \"Dogajolo Toscana Bianco 2017\"): continue\n        elif (flag == 0): \n            flag = 1\n            wine = \"Dogajolo Toscana Bianco 2017\"\n\n        #print(type(row[0]), type(row[1]), type(row[2]), type(row[3]), type(row[4]))\n        # print(type(row[2]), \"\\t\")\n        #print(\"number =\" + str(row[0]) + \"\\n\", \"year = \" + str(row[1]) + \"\\n\" + \"wine_name=\" + row[2] + \"\\n отзыв = \" + row[3], \"язык=\" + row[4] + \"\\n\")\n        # break\n        if (str(row[2]) == wine) and (row[4] == language):  # было row[2], в этот раз просто взяли без первого столбца\n            mas_notes.append(row[3])\n            continue\n        if (str(row[2]) == wine): continue\n        print(\"*********** \", wine, \" ***********\")\n        # data = pd.read_csv(\"Wines1.csv\", delimiter=\";\")\n\n        data_words = list(sent_to_words(mas_notes))\n\n        bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)  # higher threshold fewer phrases.\n        trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  # 4\n\n        # Faster way to get a sentence clubbed as a trigram/bigram\n        bigram_mod = gensim.models.phrases.Phraser(bigram)\n        trigram_mod = gensim.models.phrases.Phraser(trigram)\n\n        # See trigram example\n        # print(trigram_mod[bigram_mod[data_words[0]]])\n        # Remove Stop Words\n        data_words_nostops = remove_stopwords(data_words)\n\n        # Form Bigrams\n        data_words_bigrams = make_bigrams(data_words_nostops)\n        # print(data_words_bigrams[0])\n\n\n        # Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n        # python3 -m spacy download en\n        nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])  # en_core_web_md\n\n        # Do lemmatization keeping only noun, adj, vb, adv\n        data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n\n        # print(data_lemmatized[:1])\n        # print(data_lemmatized[1:2])\n        # print(data_lemmatized[2:3])\n        # Почему эта штука удаляет нужное\n        # Почему эта штука удаляет нужное\n\n        id2word = corpora.Dictionary(data_lemmatized)\n        texts = data_lemmatized\n        # print(texts) test output\n        corpus = [id2word.doc2bow(text) for text in texts]\n        # print(len(corpus))\n        # print([[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]])\n        # print(corpus[:1])\n\n        # Build LDA model \n        if (len(mas_notes) == 0):\n            print(\"No reviews in English\")\n            wine = row[2]\n            continue\n\n        #sys.stdout = orig_stdout\n        model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=5, limit=51, step=5)\n        #sys.stdout = f\n        limit=51\n        start=5\n        step=5\n        x = range(start, limit, step)\n        plt.cla()\n        plt.clf()\n        plt.plot(x, coherence_values)\n        plt.xlabel(\"Num Topics\")\n        plt.ylabel(\"Coherence score\")\n        plt.legend((\"coherence_values\"), loc='best')\n        plt.savefig(str('png/' + \"plot\" + \"_\"+ wine.replace(\" \", \"_\")) +'.png')\n        #plt.show()\n        optimal_model = give_optimal_model(model_list, coherence_values) #тут по идее надо исправлять\n        flag_alive = 0\n#         for i in range(2):\n#             p = Process(target=mallet_model, name=\"mallet_model\", args=(mallet_path, corpus, 5+max_i*5, id2word,))\n#             p.start()\n#             p.run()\n#             # c threads оно завершается, но видимо нельзя убить\n#             #time.sleep(70)\n#             p.join(40)\n#             if not os.path.exists(\"/kaggle/working/data.pickle\"):\n#                 print(\"mallet_model is running... let's kill it...\")\n#                 # Terminate foo\n#                 p.terminate()\n#                 p.join()\n#                 flag_alive = 1\n#             else: break\n#         for i in range(2):\n        signal.alarm(120)    \n        try:\n            model = mallet_model(mallet_path, corpus, 5+max_i*5, id2word)\n            signal.alarm(0)\n            flag_alive = 0\n            #break\n        except TimeoutException:\n            flag_alive = 1\n            print('function terminated')\n        if flag_alive == 1:\n            wine = row[2]\n            mas_notes = []\n            time.sleep(10)\n            continue\n#         with open(\"/kaggle/working/data.pickle\", 'rb') as f_1:\n#             model = pickle.load(f_1)\n        optimal_model = model\n\n        #optimal_model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=5+max_i*5, id2word=id2word)\n        #optimal_model = model\n\n        #model_topics = optimal_model.show_topics(formatted=False)\n        #pprint(optimal_model.print_topics(num_words=10))\n        #------------------------------&-----------------------------\n        df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=mas_notes) #тут\n\n        df_dominant_topic = df_topic_sents_keywords.reset_index()\n        df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n        #display(df_dominant_topic)\n\n# Show #------------------------&--------------------------------------\n        #print(df_dominant_topic.head(10))   \n        sent_topics_sorteddf_mallet = pd.DataFrame()\n\n        sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n\n        for i, grp in sent_topics_outdf_grpd:\n            sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet,grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], axis=0)\n\n# Reset Index    \n        sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n\n# Format\n        sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n\n# Show\n        #print(sent_topics_sorteddf_mallet.head())\n#-------------------------------&----------------------------\n        topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n        topic_counts = topic_counts.sort_index()\n        topic_counts = topic_counts.dropna()\n        topic_counts_new = (topic_counts.reset_index())\n        topic_counts_new = topic_counts_new.drop(columns=topic_counts_new.columns[0], axis=1)\n\n\n# Percentage of Documents for Each Topic\n        topic_contribution = (round(topic_counts/topic_counts.sum(), 4))\n        topic_contribution = topic_contribution.reset_index()\n        topic_contribution = topic_contribution.drop(columns=topic_contribution.columns[0], axis=1)\n\n# Topic Number and Keywords\n        #topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n        #print(topic_num_keywords)\n        sent_topics_sorteddf_mallet =  sent_topics_sorteddf_mallet.dropna()\n        topic_num_keywords = sent_topics_sorteddf_mallet[['Topic_Num', 'Keywords']]\n\n# Concatenate Column wise\n        df_dominant_topics = pd.concat([topic_num_keywords, topic_counts_new, topic_contribution], axis=1)\n\n\n# Change Column names\n        df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n\n# Show\n        #display(df_dominant_topics)\n\n        #save_df_as_image(df_dominant_topics,str(\"table\" + \"_\"+ wine.replace(\" \", \"_\")) +'.png')\n        df_dominant_topics.to_csv(str('csv/' + \"csv_table\" + \"_\"+ wine.replace(\" \", \"_\") +'.csv'), sep = \";\")\n#             fig = ff.create_table(df_dominant_topics)\n#             #fig.data[0]['columnwidth'] = [100, 2000]\n#             fig.update_layout({\"margin\": {\"l\": 0, \"r\": 0, \"b\": 0, \"t\": 20}, autosize=True)\n#             fig.write_image(str(\"table\" + \"_\"+ wine.replace(\" \", \"_\") +'.png'), scale=2)\n#             my_data = genfromtxt(str(\"/kaggle/working/\" + \"csv_table\" + \"_\"+ wine.replace(\" \", \"_\") +'.csv'), delimiter=';')\n#             im = Image.fromarray(my_data)\n#             if im.mode != 'RGB':\n#                 im = im.convert('RGB')\n#             im.save(\"your_file.jpeg\")\n#         display(df_dominant_topics)\n        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                                    id2word=id2word,\n                                                    num_topics=len(df_dominant_topics),\n                                                    random_state=100,\n                                                    chunksize=100,\n                                                    passes=10,\n                                                    alpha='auto',\n                                                    per_word_topics=True)\n\n        doc_lda = lda_model[corpus]\n        pyLDAvis.enable_notebook()\n        vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n        vis.topic_coordinates['x'] = np.real(vis.topic_coordinates['x'])\n        vis.topic_coordinates['y'] = np.real(vis.topic_coordinates['y'])\n        pyLDAvis.save_html(vis, str('html/' + wine.replace(\" \", \"_\") +'.html'))\n\n                                                                    \n                                                                \n        wine = row[2]\n        mas_notes = []\n        \n\n    \n    print(\"*********** \", wine, \" ***********\")\n    data_words = list(sent_to_words(mas_notes))\n\n    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)  # higher threshold fewer phrases.\n    trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  # 4\n\n    # Faster way to get a sentence clubbed as a trigram/bigram\n    bigram_mod = gensim.models.phrases.Phraser(bigram)\n    trigram_mod = gensim.models.phrases.Phraser(trigram)\n\n    # See trigram example\n    # print(trigram_mod[bigram_mod[data_words[0]]])\n    # Remove Stop Words\n    data_words_nostops = remove_stopwords(data_words)\n\n    # Form Bigrams\n    data_words_bigrams = make_bigrams(data_words_nostops)\n    # print(data_words_bigrams[0])\n\n\n    # Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n    # python3 -m spacy download en\n    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])  # en_core_web_md\n\n    # Do lemmatization keeping only noun, adj, vb, adv\n    data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n\n    id2word = corpora.Dictionary(data_lemmatized)\n    texts = data_lemmatized\n    \n    corpus = [id2word.doc2bow(text) for text in texts]\n    \n    # Build LDA model\n    if (len(mas_notes) == 0):\n        print(\"No reviews in English\")\n        wine = row[2]\n        continue\n\n#         lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n#                                                     id2word=id2word,\n#                                                     num_topics=topics,\n#                                                     random_state=100,\n#                                                     chunksize=100,\n#                                                     passes=10,\n#                                                     alpha='auto',\n#                                                     per_word_topics=True)\n\n\n\n\n#         doc_lda = lda_model[corpus]\n\n    # Compute Coherence Score\n#         coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n#         coherence_lda = coherence_model_lda.get_coherence()\n    #print('\\nCoherence Score: ', coherence_lda)\n    #sys.stdout = orig_stdout\n    model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=5, limit=51, step=5)\n    #sys.stdout = f\n    limit=51\n    start=5\n    step=5\n    x = range(start, limit, step)\n    plt.cla()\n    plt.clf()\n    plt.plot(x, coherence_values)\n    plt.xlabel(\"Num Topics\")\n    plt.ylabel(\"Coherence score\")\n    plt.legend((\"coherence_values\"), loc='best')\n    plt.savefig(str('png/' + \"plot\" + \"_\"+ wine.replace(\" \", \"_\")) +'.png')\n    #plt.show()\n    optimal_model = give_optimal_model(model_list, coherence_values)\n    #optimal_model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=5+max_i*5, id2word=id2word)\n    flag_alive = 0\n#     for i in range(2):\n#         p = multiprocessing.Process(target=mallet_model, name=\"mallet_model\", args=(mallet_path, corpus, 5+max_i*5, id2word,optimal_model,))\n#         p.start()\n#         p.join(35)\n#         if len(arr) == 0:\n#             print(\"mallet_model is running... let's kill it...\")\n\n#             # Terminate foo\n#             p.terminate()\n#             p.join()\n#             flag_alive = 1\n#         else: break\n#     if flag_alive == 1:\n#         wine = row[2]\n#         mas_notes = []\n#         continue\n#     for i in range(2):\n    signal.alarm(120)    \n    try:\n        model = mallet_model(mallet_path, corpus, 5+max_i*5, id2word)\n        signal.alarm(0)\n        flag_alive = 0\n        #break\n    except TimeoutException:\n        flag_alive = 1\n        print('function terminated')\n    if flag_alive == 1:\n        wine = row[2]\n        mas_notes = []\n        time.sleep(10)\n        continue\n    optimal_model = model\n\n    #optimal_model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=5+max_i*5, id2word=id2word)\n    #optimal_model = model\n    #model_topics = optimal_model.show_topics(formatted=False)\n    #pprint(optimal_model.print_topics(num_words=10))\n    #------------------------------&-----------------------------\n    df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=mas_notes) #тут\n\n    df_dominant_topic = df_topic_sents_keywords.reset_index()\n    df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n    # Show #------------------------&--------------------------------------\n\n    sent_topics_sorteddf_mallet = pd.DataFrame()\n\n    sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n\n    for i, grp in sent_topics_outdf_grpd:\n        sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet,grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], axis=0)\n\n# Reset Index    \n    sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n\n# Format\n    sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n\n# Show\n\n#-------------------------------&----------------------------\n    topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n    topic_counts = topic_counts.sort_index()\n    topic_counts = topic_counts.dropna()\n    topic_counts_new = (topic_counts.reset_index())\n    topic_counts_new = topic_counts_new.drop(columns=topic_counts_new.columns[0], axis=1)\n\n\n# Percentage of Documents for Each Topic\n    topic_contribution = (round(topic_counts/topic_counts.sum(), 4))\n    topic_contribution = topic_contribution.reset_index()\n    topic_contribution = topic_contribution.drop(columns=topic_contribution.columns[0], axis=1)\n\n# Topic Number and Keywords\n\n    sent_topics_sorteddf_mallet =  sent_topics_sorteddf_mallet.dropna()\n    topic_num_keywords = sent_topics_sorteddf_mallet[['Topic_Num', 'Keywords']]\n\n# Concatenate Column wise\n    df_dominant_topics = pd.concat([topic_num_keywords, topic_counts_new, topic_contribution], axis=1)\n\n\n# Change Column names\n    df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n\n# Show\n    #display(df_dominant_topics)\n    #save_df_as_image(df_dominant_topics,str(\"table\" + \"_\"+ wine.replace(\" \", \"_\")) +'.png')\n    df_dominant_topics.to_csv(str('csv/' + \"csv_table\" + \"_\"+ wine.replace(\" \", \"_\") +'.csv'), sep = \";\")\n#         fig = ff.create_table(df_dominant_topics)\n#         fig.update_layout(\n#                     autosize=False,\n#                     )\n#         fig.write_image(str(\"table\" + \"_\"+ wine.replace(\" \", \"_\") +'.png'), scale=2)\n    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                                    id2word=id2word,\n                                                    num_topics=len(df_dominant_topics),\n                                                    random_state=100,\n                                                    chunksize=100,\n                                                    passes=10,\n                                                    alpha='auto',\n                                                    per_word_topics=True)\n\n    doc_lda = lda_model[corpus]\n    pyLDAvis.enable_notebook()\n    vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n    vis.topic_coordinates['x'] = np.real(vis.topic_coordinates['x'])\n    vis.topic_coordinates['y'] = np.real(vis.topic_coordinates['y'])\n    pyLDAvis.save_html(vis, str('html/' + wine.replace(\" \", \"_\") +'.html'))\n\n    sys.stdout = orig_stdout\n    f.close()\n","metadata":{"execution":{"iopub.status.busy":"2022-12-20T23:44:01.629308Z","iopub.execute_input":"2022-12-20T23:44:01.630020Z","iopub.status.idle":"2022-12-20T23:47:09.420583Z","shell.execute_reply.started":"2022-12-20T23:44:01.629982Z","shell.execute_reply":"2022-12-20T23:47:09.419100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}